<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Nicholas Chu">

<title>PIC16B-23F - Dogs, Cats, and Tensorflow</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">PIC16B-23F</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/PIC16B-23F" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Dogs, Cats, and Tensorflow</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Nicholas Chu </p>
            </div>
    </div>
      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#using-tensorflow-to-classify-dogs-and-cats" id="toc-using-tensorflow-to-classify-dogs-and-cats" class="nav-link active" data-scroll-target="#using-tensorflow-to-classify-dogs-and-cats">Using Tensorflow to Classify Dogs and Cats</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">1. Introduction</a>
  <ul class="collapse">
  <li><a href="#load-correct-data" id="toc-load-correct-data" class="nav-link" data-scroll-target="#load-correct-data">Load correct data</a></li>
  <li><a href="#visualize-the-data" id="toc-visualize-the-data" class="nav-link" data-scroll-target="#visualize-the-data">Visualize the Data</a></li>
  <li><a href="#analyzing-our-labels" id="toc-analyzing-our-labels" class="nav-link" data-scroll-target="#analyzing-our-labels">Analyzing Our Labels</a></li>
  </ul></li>
  <li><a href="#first-simple-model" id="toc-first-simple-model" class="nav-link" data-scroll-target="#first-simple-model">2. First Simple Model</a>
  <ul class="collapse">
  <li><a href="#model-1-comments" id="toc-model-1-comments" class="nav-link" data-scroll-target="#model-1-comments">Model 1 Comments</a></li>
  </ul></li>
  <li><a href="#second-model-data-augmentation-layers" id="toc-second-model-data-augmentation-layers" class="nav-link" data-scroll-target="#second-model-data-augmentation-layers">3. Second Model (Data Augmentation Layers)</a>
  <ul class="collapse">
  <li><a href="#comments-on-model-2" id="toc-comments-on-model-2" class="nav-link" data-scroll-target="#comments-on-model-2">Comments on Model 2:</a></li>
  </ul></li>
  <li><a href="#third-model-data-preprocessing" id="toc-third-model-data-preprocessing" class="nav-link" data-scroll-target="#third-model-data-preprocessing">4. Third Model (Data Preprocessing)</a>
  <ul class="collapse">
  <li><a href="#comments-on-model-3" id="toc-comments-on-model-3" class="nav-link" data-scroll-target="#comments-on-model-3">Comments on Model 3:</a></li>
  </ul></li>
  <li><a href="#last-model-transfer-learning" id="toc-last-model-transfer-learning" class="nav-link" data-scroll-target="#last-model-transfer-learning">5. Last Model (Transfer Learning)</a>
  <ul class="collapse">
  <li><a href="#comments-on-model-4" id="toc-comments-on-model-4" class="nav-link" data-scroll-target="#comments-on-model-4">Comments on Model 4:</a></li>
  </ul></li>
  <li><a href="#evaluating-testing-data-using-best-model" id="toc-evaluating-testing-data-using-best-model" class="nav-link" data-scroll-target="#evaluating-testing-data-using-best-model">6. Evaluating Testing Data Using Best Model</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="using-tensorflow-to-classify-dogs-and-cats" class="level1">
<h1>Using Tensorflow to Classify Dogs and Cats</h1>
</section>
<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>First, let’s import some important packages. We need <code>tensorflow.keras</code> for the ML algorithm, and its appropriate modules for other uses. We will also import some other packages like <code>numpy</code>, etc.</p>
<div class="cell" data-tags="[]" data-execution_count="9">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> utils</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> datasets, layers, models</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.signal <span class="im">import</span> convolve2d</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># mute all tensorflow warnings</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="load-correct-data" class="level2">
<h2 class="anchored" data-anchor-id="load-correct-data">Load correct data</h2>
<p>Now, let’s load the sample data, consisting of labeled images of dogs and cats. We run the following code to extract the data and create training, testing, and validation datasets.</p>
<div class="cell" data-outputid="d13060d7-f9c7-41e1-9599-14640ba647b5" data-tags="[]" data-execution_count="10">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># location of data</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>_URL <span class="op">=</span> <span class="st">'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># download the data and extract it</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>path_to_zip <span class="op">=</span> utils.get_file(<span class="st">'cats_and_dogs.zip'</span>, origin<span class="op">=</span>_URL, extract<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># construct paths</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>PATH <span class="op">=</span> os.path.join(os.path.dirname(path_to_zip), <span class="st">'cats_and_dogs_filtered'</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>train_dir <span class="op">=</span> os.path.join(PATH, <span class="st">'train'</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>validation_dir <span class="op">=</span> os.path.join(PATH, <span class="st">'validation'</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co"># parameters for datasets</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>IMG_SIZE <span class="op">=</span> (<span class="dv">160</span>, <span class="dv">160</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="co"># construct train and validation datasets</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> utils.image_dataset_from_directory(train_dir,</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>                                                   shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>                                                   batch_size<span class="op">=</span>BATCH_SIZE,</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>                                                   image_size<span class="op">=</span>IMG_SIZE)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>validation_dataset <span class="op">=</span> utils.image_dataset_from_directory(validation_dir,</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>                                                        shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>                                                        batch_size<span class="op">=</span>BATCH_SIZE,</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>                                                        image_size<span class="op">=</span>IMG_SIZE)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="co"># construct the test dataset by taking every 5th observation out of the validation dataset</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>val_batches <span class="op">=</span> tf.data.experimental.cardinality(validation_dataset)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> validation_dataset.take(val_batches <span class="op">//</span> <span class="dv">5</span>)</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>validation_dataset <span class="op">=</span> validation_dataset.skip(val_batches <span class="op">//</span> <span class="dv">5</span>)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a><span class="co">#create class names for the training set</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>class_names <span class="op">=</span> train_dataset.class_names</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Found 2000 files belonging to 2 classes.
Found 1000 files belonging to 2 classes.</code></pre>
</div>
</div>
<p>Next, the following code will help us read data with better performance:</p>
<div class="cell" data-tags="[]" data-execution_count="11">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>AUTOTUNE <span class="op">=</span> tf.data.AUTOTUNE</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> train_dataset.prefetch(buffer_size<span class="op">=</span>AUTOTUNE)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>validation_dataset <span class="op">=</span> validation_dataset.prefetch(buffer_size<span class="op">=</span>AUTOTUNE)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> test_dataset.prefetch(buffer_size<span class="op">=</span>AUTOTUNE)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="visualize-the-data" class="level2">
<h2 class="anchored" data-anchor-id="visualize-the-data">Visualize the Data</h2>
<p>We can visualize the data via a function called <code>visualize_data</code> that will take in our training dataset as a parameter. We use <code>dataset.take(1)</code> to access the 1st batch (32 images with labels) from the dataset. We iterate through this batch and output the first 3 cat images in the 1st row, and the first 3 dog images into the 2nd row.</p>
<div class="cell" data-outputid="50993dd7-c082-4a86-89e8-fcefe67033d1" data-tags="[]" data-execution_count="12">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> visualize_data(dataset):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> images, labels <span class="kw">in</span> dataset.take(<span class="dv">1</span>):</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>        i <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        cats <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>        dogs <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">32</span>):</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> (labels[i].numpy() <span class="op">==</span> <span class="dv">0</span>):</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> cats <span class="op">&lt;=</span> <span class="dv">3</span>:</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>                    ax <span class="op">=</span> plt.subplot(<span class="dv">3</span>, <span class="dv">3</span>, cats)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>                    plt.imshow(images[i].numpy().astype(<span class="st">"uint8"</span>))</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>                    plt.title(class_names[labels[i]])</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>                    plt.axis(<span class="st">"off"</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>                    cats <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>                    i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> (labels[i].numpy() <span class="op">==</span> <span class="dv">1</span>):</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> dogs <span class="op">&lt;=</span> <span class="dv">6</span>:</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>                    ax <span class="op">=</span> plt.subplot(<span class="dv">3</span>, <span class="dv">3</span>, dogs)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>                    plt.imshow(images[i].numpy().astype(<span class="st">"uint8"</span>))</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>                    plt.title(class_names[labels[i]])</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>                    plt.axis(<span class="st">"off"</span>)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>                    dogs <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>                    i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>visualize_data(train_dataset)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-5-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="analyzing-our-labels" class="level2">
<h2 class="anchored" data-anchor-id="analyzing-our-labels">Analyzing Our Labels</h2>
<p>Next, we will create an iterator called <code>labels_iterator</code>, where we will iterate through <code>labels_iterator</code> to see the number of cat and dog images in the training data respectively.</p>
<div class="cell" data-outputid="77a30cb9-cdc1-4a3c-a84b-6adadd2e7301" data-tags="[]" data-execution_count="13">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>labels_iterator <span class="op">=</span> train_dataset.unbatch().<span class="bu">map</span>(<span class="kw">lambda</span> image, label: label).as_numpy_iterator()</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>cats <span class="op">=</span> dogs <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> element <span class="kw">in</span> labels_iterator:</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> element <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        cats <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>        dogs <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>cats, dogs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>(1000, 1000)</code></pre>
</div>
</div>
<p>Looks like we have 1000 images of each animal in our training set. If we were to create our baseline machine learning model where the model always guesses the most frequent label, then neither cat or dog would take up the majority. Therefore, if we were to suppose that all images were labeled as dogs as the baseline machine learning model, then our model would only be <strong>50% accurate</strong>, so we can definitely improve upon this.</p>
</section>
</section>
<section id="first-simple-model" class="level1">
<h1>2. First Simple Model</h1>
<p>Let’s create our first model with <code>tf.keras.Sequential</code> using three <code>Conv2d</code> layers, 2 <code>MaxPooling2D</code> layers, 1 <code>Flatten</code> layer, 2 <code>Dense</code> layers, and 1 <code>Dropout</code> layer.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>model1 <span class="op">=</span> models.Sequential([</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>, input_shape<span class="op">=</span>(<span class="dv">160</span>, <span class="dv">160</span>, <span class="dv">3</span>)),</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    layers.Flatten(),</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    layers.Dropout(<span class="fl">.15</span>),</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">2</span>)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s look at the model’s summary:</p>
<div class="cell" data-outputid="480bd287-a6e9-495a-bb35-4075e5fa889e" data-execution_count="15">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>model1.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 158, 158, 32)      896       
                                                                 
 max_pooling2d (MaxPooling2  (None, 79, 79, 32)        0         
 D)                                                              
                                                                 
 conv2d_1 (Conv2D)           (None, 77, 77, 32)        9248      
                                                                 
 max_pooling2d_1 (MaxPoolin  (None, 38, 38, 32)        0         
 g2D)                                                            
                                                                 
 conv2d_2 (Conv2D)           (None, 36, 36, 64)        18496     
                                                                 
 flatten (Flatten)           (None, 82944)             0         
                                                                 
 dense (Dense)               (None, 64)                5308480   
                                                                 
 dropout (Dropout)           (None, 64)                0         
                                                                 
 dense_1 (Dense)             (None, 2)                 130       
                                                                 
=================================================================
Total params: 5337250 (20.36 MB)
Trainable params: 5337250 (20.36 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________</code></pre>
</div>
</div>
<p>We use <code>2D convolution</code> layers with the 1st argument representing the dimensionality of the output filter, the 2nd representing the kernel size, the 3rd representing the activation method, and (for the 1st convolution), the last argument being the input shape. We use <code>maxpooling</code> in between the convolutions in order to create a downsampled map and help with overfitting. We use a <code>flatten</code> layer next to create a fully connected layer. Then, we use a <code>dense</code> layer to reduce the output shape and add extra parameters and then a <code>dropout</code> layer to once again help with overfitting. Finally, we use a final <code>dense</code> layer with 2 as our argument since we have 2 classes in our dataset and want our final classification to be either of these 2 classes, cat or dog.</p>
<p>Now, we can compile the model with our oprtimizer as <code>adam</code>, loss function as <code>SparseCategoricalCrossentropy(from_logits=True)</code>, and metrics as <code>accuracy</code>, and then train for 20 epochs.</p>
<div class="cell" data-outputid="897df626-8003-44fb-ffbe-3762f6ec96b5" data-execution_count="28">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>model1.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>              loss <span class="op">=</span> tf.keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>              metrics <span class="op">=</span> [<span class="st">'accuracy'</span>])</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model1.fit(train_dataset,</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>                     epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>                     validation_data<span class="op">=</span>validation_dataset)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20
63/63 [==============================] - 5s 50ms/step - loss: 0.1232 - accuracy: 0.9655 - val_loss: 5.2037 - val_accuracy: 0.5594
Epoch 2/20
63/63 [==============================] - 4s 64ms/step - loss: 0.2014 - accuracy: 0.9575 - val_loss: 5.6181 - val_accuracy: 0.5384
Epoch 3/20
63/63 [==============================] - 3s 48ms/step - loss: 0.1085 - accuracy: 0.9725 - val_loss: 19.5345 - val_accuracy: 0.5285
Epoch 4/20
63/63 [==============================] - 3s 48ms/step - loss: 0.6302 - accuracy: 0.9120 - val_loss: 5.4655 - val_accuracy: 0.5198
Epoch 5/20
63/63 [==============================] - 5s 83ms/step - loss: 0.1631 - accuracy: 0.9505 - val_loss: 6.1352 - val_accuracy: 0.5594
Epoch 6/20
63/63 [==============================] - 3s 49ms/step - loss: 0.2192 - accuracy: 0.9420 - val_loss: 6.3172 - val_accuracy: 0.5309
Epoch 7/20
63/63 [==============================] - 3s 49ms/step - loss: 0.0533 - accuracy: 0.9800 - val_loss: 6.5065 - val_accuracy: 0.5322
Epoch 8/20
63/63 [==============================] - 6s 89ms/step - loss: 0.0424 - accuracy: 0.9825 - val_loss: 6.1610 - val_accuracy: 0.5124
Epoch 9/20
63/63 [==============================] - 4s 64ms/step - loss: 0.0355 - accuracy: 0.9865 - val_loss: 5.9597 - val_accuracy: 0.5371
Epoch 10/20
63/63 [==============================] - 6s 90ms/step - loss: 0.0958 - accuracy: 0.9830 - val_loss: 8.6715 - val_accuracy: 0.5891
Epoch 11/20
63/63 [==============================] - 4s 54ms/step - loss: 0.1063 - accuracy: 0.9785 - val_loss: 8.6982 - val_accuracy: 0.5545
Epoch 12/20
63/63 [==============================] - 3s 50ms/step - loss: 0.0850 - accuracy: 0.9830 - val_loss: 6.1948 - val_accuracy: 0.5780
Epoch 13/20
63/63 [==============================] - 6s 91ms/step - loss: 0.0229 - accuracy: 0.9940 - val_loss: 6.3688 - val_accuracy: 0.5507
Epoch 14/20
63/63 [==============================] - 3s 49ms/step - loss: 0.0403 - accuracy: 0.9895 - val_loss: 7.1590 - val_accuracy: 0.5557
Epoch 15/20
63/63 [==============================] - 3s 50ms/step - loss: 0.0757 - accuracy: 0.9845 - val_loss: 7.1530 - val_accuracy: 0.5495
Epoch 16/20
63/63 [==============================] - 6s 98ms/step - loss: 0.2257 - accuracy: 0.9705 - val_loss: 6.2619 - val_accuracy: 0.5359
Epoch 17/20
63/63 [==============================] - 7s 100ms/step - loss: 0.0761 - accuracy: 0.9825 - val_loss: 5.4714 - val_accuracy: 0.5408
Epoch 18/20
63/63 [==============================] - 8s 110ms/step - loss: 0.0295 - accuracy: 0.9895 - val_loss: 6.9426 - val_accuracy: 0.5248
Epoch 19/20
63/63 [==============================] - 4s 53ms/step - loss: 0.0147 - accuracy: 0.9970 - val_loss: 6.0135 - val_accuracy: 0.5532
Epoch 20/20
63/63 [==============================] - 6s 86ms/step - loss: 0.0170 - accuracy: 0.9960 - val_loss: 6.9712 - val_accuracy: 0.5446</code></pre>
</div>
</div>
<p>Next, let’s plot the accuracy of the training and validation sets across the 20 epochs.</p>
<div class="cell" data-outputid="a597f261-2a51-4035-b2e5-df5837717d03" data-execution_count="29">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"accuracy"</span>], label <span class="op">=</span> <span class="st">"training"</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_accuracy"</span>], label <span class="op">=</span> <span class="st">"validation"</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"epoch"</span>, ylabel <span class="op">=</span> <span class="st">"accuracy"</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>&lt;matplotlib.legend.Legend at 0x789198bf94e0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-10-output-2.png" class="img-fluid"></p>
</div>
</div>
<section id="model-1-comments" class="level2">
<h2 class="anchored" data-anchor-id="model-1-comments">Model 1 Comments</h2>
<ul>
<li>I experimented with the parameter for the Dropout layer. After a couple of tests, value of .15 gave me the best accuracies</li>
<li><strong><em>The accuracy of the model stabilized between around 53% and 59%</em></strong></li>
<li>Compared with baseline of 50%, this model definitely did better, but around 60% accuracy still isn’t ideal</li>
<li>There is a huge overfitting issue on Model 1. In the graph, the accuracy on the training data jumps much higher than the accuracy on the validation data, so the model is clearly fitting far too close to the training data.</li>
</ul>
<hr>
</section>
</section>
<section id="second-model-data-augmentation-layers" class="level1">
<h1>3. Second Model (Data Augmentation Layers)</h1>
<p>Now, we will explore data augmentation with <code>RandomFlip</code> and <code>RandomRotation</code>, which will flip and rotate some of the images. Our goal is to have our model learn to recognize these images as ones that are just transformed versions of the original images.</p>
<p>First, let’s create our 2 layers, each holding <code>RandomFlip</code> and <code>RandomRotation</code> respectively, and then we create another layer that combines the 2 so that we can use it for the model later.</p>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>random_flip <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.RandomFlip(<span class="st">'horizontal'</span>, input_shape<span class="op">=</span>(<span class="dv">160</span>,<span class="dv">160</span>,<span class="dv">3</span>))</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>random_rotation <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.RandomRotation(<span class="fl">0.2</span>, input_shape<span class="op">=</span>(<span class="dv">160</span>,<span class="dv">160</span>,<span class="dv">3</span>))</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>data_augmentation <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.RandomFlip(<span class="st">'horizontal'</span>, input_shape<span class="op">=</span>(<span class="dv">160</span>,<span class="dv">160</span>,<span class="dv">3</span>)),</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.RandomRotation(<span class="fl">0.2</span>),</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, we can take in the 1st random image in the training dataset batch and apply <code>random_flip</code> and <code>random_rotation</code> separately. We should expect 2 plots with 6 images each.</p>
<div class="cell" data-outputid="f1de887e-b81b-4858-d036-f0fe815bb654" data-execution_count="31">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> image, _ <span class="kw">in</span> train_dataset.take(<span class="dv">1</span>):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>  first_image <span class="op">=</span> image[<span class="dv">0</span>]</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">6</span>):</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> plt.subplot(<span class="dv">3</span>, <span class="dv">3</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    augmented_image <span class="op">=</span> random_flip(tf.expand_dims(first_image, <span class="dv">0</span>))</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    plt.imshow(augmented_image[<span class="dv">0</span>] <span class="op">/</span> <span class="dv">255</span>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> image, _ <span class="kw">in</span> train_dataset.take(<span class="dv">1</span>):</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>  plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>  first_image <span class="op">=</span> image[<span class="dv">0</span>]</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">6</span>):</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> plt.subplot(<span class="dv">3</span>, <span class="dv">3</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    augmented_image <span class="op">=</span> random_rotation(tf.expand_dims(first_image, <span class="dv">0</span>))</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    plt.imshow(augmented_image[<span class="dv">0</span>] <span class="op">/</span> <span class="dv">255</span>)</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-12-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-12-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>In the first plots, the layer <code>Randomflip</code> flipped the image horizontally as we specified. In the second plots, the layer <code>RandomRotation</code> was able to rotate the image by a certain amount. So, we are now ready to build our revised model!</p>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> models.Sequential([</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    data_augmentation,</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    layers.Flatten(),</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    layers.Dropout(<span class="fl">.15</span>),</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">2</span>)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Again, let’s look at this model’s summary:</p>
<div class="cell" data-outputid="4220e14b-ea1f-4d09-a002-f639ff61c7d2" data-execution_count="33">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>model2.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_8"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_7 (Sequential)   (None, 160, 160, 3)       0         
                                                                 
 conv2d_6 (Conv2D)           (None, 158, 158, 32)      896       
                                                                 
 max_pooling2d_4 (MaxPoolin  (None, 79, 79, 32)        0         
 g2D)                                                            
                                                                 
 conv2d_7 (Conv2D)           (None, 77, 77, 32)        9248      
                                                                 
 max_pooling2d_5 (MaxPoolin  (None, 38, 38, 32)        0         
 g2D)                                                            
                                                                 
 conv2d_8 (Conv2D)           (None, 36, 36, 64)        18496     
                                                                 
 flatten_2 (Flatten)         (None, 82944)             0         
                                                                 
 dropout_2 (Dropout)         (None, 82944)             0         
                                                                 
 dense_4 (Dense)             (None, 64)                5308480   
                                                                 
 dense_5 (Dense)             (None, 2)                 130       
                                                                 
=================================================================
Total params: 5337250 (20.36 MB)
Trainable params: 5337250 (20.36 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________</code></pre>
</div>
</div>
<p>Now, we can train the model:</p>
<div class="cell" data-outputid="0f992ffc-491b-46a0-c91b-241532c90b3e" data-execution_count="34">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>model2.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>              loss <span class="op">=</span> tf.keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>              metrics <span class="op">=</span> [<span class="st">'accuracy'</span>])</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model2.fit(train_dataset,</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>                     epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>                     validation_data<span class="op">=</span>validation_dataset)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20
63/63 [==============================] - 7s 81ms/step - loss: 42.2194 - accuracy: 0.5270 - val_loss: 0.6964 - val_accuracy: 0.5619
Epoch 2/20
63/63 [==============================] - 3s 50ms/step - loss: 0.7003 - accuracy: 0.5465 - val_loss: 0.6918 - val_accuracy: 0.5322
Epoch 3/20
63/63 [==============================] - 3s 49ms/step - loss: 0.6848 - accuracy: 0.5805 - val_loss: 0.6885 - val_accuracy: 0.5681
Epoch 4/20
63/63 [==============================] - 4s 55ms/step - loss: 0.6783 - accuracy: 0.5845 - val_loss: 0.6998 - val_accuracy: 0.5606
Epoch 5/20
63/63 [==============================] - 4s 52ms/step - loss: 0.6701 - accuracy: 0.5890 - val_loss: 0.7419 - val_accuracy: 0.5854
Epoch 6/20
63/63 [==============================] - 3s 50ms/step - loss: 0.6710 - accuracy: 0.6200 - val_loss: 0.6930 - val_accuracy: 0.5891
Epoch 7/20
63/63 [==============================] - 3s 50ms/step - loss: 0.6723 - accuracy: 0.5880 - val_loss: 0.6931 - val_accuracy: 0.5681
Epoch 8/20
63/63 [==============================] - 5s 80ms/step - loss: 0.6805 - accuracy: 0.6075 - val_loss: 0.7302 - val_accuracy: 0.5557
Epoch 9/20
63/63 [==============================] - 3s 49ms/step - loss: 0.6710 - accuracy: 0.5885 - val_loss: 0.6936 - val_accuracy: 0.5879
Epoch 10/20
63/63 [==============================] - 4s 56ms/step - loss: 0.6638 - accuracy: 0.6010 - val_loss: 0.6969 - val_accuracy: 0.5619
Epoch 11/20
63/63 [==============================] - 5s 77ms/step - loss: 0.6748 - accuracy: 0.5985 - val_loss: 0.6815 - val_accuracy: 0.5916
Epoch 12/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6640 - accuracy: 0.6195 - val_loss: 0.7009 - val_accuracy: 0.5903
Epoch 13/20
63/63 [==============================] - 4s 66ms/step - loss: 0.6388 - accuracy: 0.6445 - val_loss: 0.6898 - val_accuracy: 0.5941
Epoch 14/20
63/63 [==============================] - 6s 94ms/step - loss: 0.6449 - accuracy: 0.6290 - val_loss: 0.6766 - val_accuracy: 0.6040
Epoch 15/20
63/63 [==============================] - 3s 52ms/step - loss: 0.6379 - accuracy: 0.6500 - val_loss: 0.6782 - val_accuracy: 0.6324
Epoch 16/20
63/63 [==============================] - 8s 114ms/step - loss: 0.6615 - accuracy: 0.6105 - val_loss: 0.6720 - val_accuracy: 0.5978
Epoch 17/20
63/63 [==============================] - 4s 54ms/step - loss: 0.6500 - accuracy: 0.6290 - val_loss: 0.6831 - val_accuracy: 0.5606
Epoch 18/20
63/63 [==============================] - 3s 49ms/step - loss: 0.6553 - accuracy: 0.6130 - val_loss: 0.6682 - val_accuracy: 0.5953
Epoch 19/20
63/63 [==============================] - 5s 74ms/step - loss: 0.6483 - accuracy: 0.6120 - val_loss: 0.6594 - val_accuracy: 0.6151
Epoch 20/20
63/63 [==============================] - 4s 51ms/step - loss: 0.6496 - accuracy: 0.6180 - val_loss: 0.6575 - val_accuracy: 0.6423</code></pre>
</div>
</div>
<p>Now, let’s plot and take a look at what’s going on with our new model!</p>
<div class="cell" data-outputid="bc490479-cc22-4b8f-bd36-c159c456a5d0" data-execution_count="35">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"accuracy"</span>], label <span class="op">=</span> <span class="st">"training"</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_accuracy"</span>], label <span class="op">=</span> <span class="st">"validation"</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"epoch"</span>, ylabel <span class="op">=</span> <span class="st">"accuracy"</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>&lt;matplotlib.legend.Legend at 0x7891989ffa60&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-16-output-2.png" class="img-fluid"></p>
</div>
</div>
<section id="comments-on-model-2" class="level2">
<h2 class="anchored" data-anchor-id="comments-on-model-2">Comments on Model 2:</h2>
<ul>
<li><strong><em>The accuracy of my model stabilized between 55 and 63%</em></strong></li>
<li>Compared with the baseline of 50%, this model did better than that, but did not make much improvement from <code>model1</code>.</li>
<li>Still some overfitting, but definitely not as bad as <code>model1</code>. We want to avoid as much of this as possible though however.</li>
</ul>
<hr>
</section>
</section>
<section id="third-model-data-preprocessing" class="level1">
<h1>4. Third Model (Data Preprocessing)</h1>
<p>Let’s now add data preprocessing, such as scaling the RGB code down into something easier to compute. We will create a preprocessor layer in which we can insert into the beginning of our model:</p>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> tf.keras.Input(shape<span class="op">=</span>(<span class="dv">160</span>, <span class="dv">160</span>, <span class="dv">3</span>))</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> tf.keras.applications.mobilenet_v2.preprocess_input(i)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>preprocessor <span class="op">=</span> tf.keras.Model(inputs <span class="op">=</span> [i], outputs <span class="op">=</span> [x])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, here is our <code>model3</code> with the preprocessor layer:</p>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>model3 <span class="op">=</span> models.Sequential([</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    preprocessor,</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    data_augmentation,</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    layers.Flatten(),</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>    layers.Dropout(<span class="fl">.15</span>),</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">2</span>)</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s look at the summary:</p>
<div class="cell" data-outputid="5ae3f427-b888-4bd3-da8b-cb45404b968e" data-execution_count="38">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>model3.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 model (Functional)          (None, 160, 160, 3)       0         
                                                                 
 sequential_7 (Sequential)   (None, 160, 160, 3)       0         
                                                                 
 conv2d_9 (Conv2D)           (None, 158, 158, 32)      896       
                                                                 
 max_pooling2d_6 (MaxPoolin  (None, 79, 79, 32)        0         
 g2D)                                                            
                                                                 
 conv2d_10 (Conv2D)          (None, 77, 77, 32)        9248      
                                                                 
 max_pooling2d_7 (MaxPoolin  (None, 38, 38, 32)        0         
 g2D)                                                            
                                                                 
 conv2d_11 (Conv2D)          (None, 36, 36, 64)        18496     
                                                                 
 flatten_3 (Flatten)         (None, 82944)             0         
                                                                 
 dropout_3 (Dropout)         (None, 82944)             0         
                                                                 
 dense_6 (Dense)             (None, 64)                5308480   
                                                                 
 dense_7 (Dense)             (None, 2)                 130       
                                                                 
=================================================================
Total params: 5337250 (20.36 MB)
Trainable params: 5337250 (20.36 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________</code></pre>
</div>
</div>
<p>Now, we train:</p>
<div class="cell" data-outputid="ea97c774-f1b1-4e9f-93ea-019691bc2c99" data-execution_count="40">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>model3.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>              loss <span class="op">=</span> tf.keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>              metrics <span class="op">=</span> [<span class="st">'accuracy'</span>])</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model3.fit(train_dataset,</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>                     epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>                     validation_data<span class="op">=</span>validation_dataset)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20
63/63 [==============================] - 5s 51ms/step - loss: 0.7249 - accuracy: 0.5135 - val_loss: 0.6747 - val_accuracy: 0.6077
Epoch 2/20
63/63 [==============================] - 4s 56ms/step - loss: 0.6822 - accuracy: 0.5450 - val_loss: 0.6496 - val_accuracy: 0.6064
Epoch 3/20
63/63 [==============================] - 6s 93ms/step - loss: 0.6552 - accuracy: 0.5920 - val_loss: 0.6458 - val_accuracy: 0.6015
Epoch 4/20
63/63 [==============================] - 4s 60ms/step - loss: 0.6514 - accuracy: 0.6090 - val_loss: 0.6421 - val_accuracy: 0.6089
Epoch 5/20
63/63 [==============================] - 4s 55ms/step - loss: 0.6239 - accuracy: 0.6325 - val_loss: 0.6306 - val_accuracy: 0.6312
Epoch 6/20
63/63 [==============================] - 5s 81ms/step - loss: 0.6232 - accuracy: 0.6295 - val_loss: 0.6321 - val_accuracy: 0.6300
Epoch 7/20
63/63 [==============================] - 4s 55ms/step - loss: 0.5992 - accuracy: 0.6655 - val_loss: 0.5764 - val_accuracy: 0.6894
Epoch 8/20
63/63 [==============================] - 3s 52ms/step - loss: 0.5784 - accuracy: 0.6845 - val_loss: 0.5719 - val_accuracy: 0.7067
Epoch 9/20
63/63 [==============================] - 4s 59ms/step - loss: 0.5650 - accuracy: 0.7045 - val_loss: 0.6074 - val_accuracy: 0.6881
Epoch 10/20
63/63 [==============================] - 4s 50ms/step - loss: 0.5756 - accuracy: 0.6765 - val_loss: 0.5964 - val_accuracy: 0.6894
Epoch 11/20
63/63 [==============================] - 3s 50ms/step - loss: 0.5749 - accuracy: 0.7090 - val_loss: 0.5830 - val_accuracy: 0.6869
Epoch 12/20
63/63 [==============================] - 3s 49ms/step - loss: 0.5605 - accuracy: 0.7095 - val_loss: 0.5721 - val_accuracy: 0.7079
Epoch 13/20
63/63 [==============================] - 5s 82ms/step - loss: 0.5530 - accuracy: 0.7140 - val_loss: 0.5847 - val_accuracy: 0.7104
Epoch 14/20
63/63 [==============================] - 3s 50ms/step - loss: 0.5259 - accuracy: 0.7300 - val_loss: 0.5579 - val_accuracy: 0.7302
Epoch 15/20
63/63 [==============================] - 3s 50ms/step - loss: 0.5197 - accuracy: 0.7360 - val_loss: 0.5724 - val_accuracy: 0.7153
Epoch 16/20
63/63 [==============================] - 5s 77ms/step - loss: 0.5291 - accuracy: 0.7205 - val_loss: 0.5371 - val_accuracy: 0.7438
Epoch 17/20
63/63 [==============================] - 4s 55ms/step - loss: 0.5091 - accuracy: 0.7425 - val_loss: 0.5750 - val_accuracy: 0.7153
Epoch 18/20
63/63 [==============================] - 3s 50ms/step - loss: 0.5117 - accuracy: 0.7535 - val_loss: 0.5457 - val_accuracy: 0.7067
Epoch 19/20
63/63 [==============================] - 3s 51ms/step - loss: 0.4971 - accuracy: 0.7445 - val_loss: 0.5256 - val_accuracy: 0.7376
Epoch 20/20
63/63 [==============================] - 5s 76ms/step - loss: 0.4775 - accuracy: 0.7630 - val_loss: 0.5483 - val_accuracy: 0.7413</code></pre>
</div>
</div>
<p>Taking a look at the graph:</p>
<div class="cell" data-outputid="393fbf8c-2adc-4f31-c9a0-4d23895d682b" data-execution_count="41">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"accuracy"</span>], label <span class="op">=</span> <span class="st">"training"</span>)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_accuracy"</span>], label <span class="op">=</span> <span class="st">"validation"</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"epoch"</span>, ylabel <span class="op">=</span> <span class="st">"accuracy"</span>)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>&lt;matplotlib.legend.Legend at 0x78921010e770&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-21-output-2.png" class="img-fluid"></p>
</div>
</div>
<section id="comments-on-model-3" class="level2">
<h2 class="anchored" data-anchor-id="comments-on-model-3">Comments on Model 3:</h2>
<ul>
<li><strong><em>The accuracy of my model stabilized between 70% and 75%.</em></strong></li>
<li>This result is slightly better than <code>model2</code>, so we are improving!</li>
<li>Huge fix with this revised model is that we have less overfitting for sure. The validation accuracy is nearly aligned with the training accuracy.</li>
</ul>
</section>
</section>
<section id="last-model-transfer-learning" class="level1">
<h1>5. Last Model (Transfer Learning)</h1>
<p>In this final model, we will use a pre-existing model that somebody else has created and incorporate it into a full model for our task. The following code is from a base cmodel from <code>MobileNetV2</code> that we will use to see if it improves our model!</p>
<div class="cell" data-outputid="569b2112-0471-439d-a4d3-22c7618a34a0" data-execution_count="42">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>IMG_SHAPE <span class="op">=</span> IMG_SIZE <span class="op">+</span> (<span class="dv">3</span>,)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>base_model <span class="op">=</span> tf.keras.applications.MobileNetV2(input_shape<span class="op">=</span>IMG_SHAPE,</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>                                               include_top<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>                                               weights<span class="op">=</span><span class="st">'imagenet'</span>)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>base_model.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> tf.keras.Input(shape<span class="op">=</span>IMG_SHAPE)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> base_model(i, training <span class="op">=</span> <span class="va">False</span>)</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>base_model_layer <span class="op">=</span> tf.keras.Model(inputs <span class="op">=</span> [i], outputs <span class="op">=</span> [x])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5
9406464/9406464 [==============================] - 1s 0us/step</code></pre>
</div>
</div>
<p>After adding <code>base_model_layer</code>, we now do the same process:</p>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>model4 <span class="op">=</span> models.Sequential([</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>    preprocessor,</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>    data_augmentation,</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    base_model_layer,</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>    layers.GlobalMaxPooling2D(),</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>    layers.Dropout(<span class="fl">.2</span>),</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">2</span>)</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Summary:</p>
<div class="cell" data-outputid="e3d364b3-a2f6-493d-dbf7-06080f488105" data-execution_count="44">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>model4.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_10"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 model (Functional)          (None, 160, 160, 3)       0         
                                                                 
 sequential_7 (Sequential)   (None, 160, 160, 3)       0         
                                                                 
 model_1 (Functional)        (None, 5, 5, 1280)        2257984   
                                                                 
 global_max_pooling2d (Glob  (None, 1280)              0         
 alMaxPooling2D)                                                 
                                                                 
 dropout_4 (Dropout)         (None, 1280)              0         
                                                                 
 dense_8 (Dense)             (None, 2)                 2562      
                                                                 
=================================================================
Total params: 2260546 (8.62 MB)
Trainable params: 2562 (10.01 KB)
Non-trainable params: 2257984 (8.61 MB)
_________________________________________________________________</code></pre>
</div>
</div>
<p>From the summary, we can see that we have 2257984 parameters to train for the base_model_layer!</p>
<p>Training:</p>
<div class="cell" data-outputid="8604d222-4f94-49e2-9f0a-b8854ef46026" data-execution_count="47">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>model4.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>              loss <span class="op">=</span> tf.keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>              metrics <span class="op">=</span> [<span class="st">'accuracy'</span>])</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model4.fit(train_dataset,</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>                     epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>                     validation_data<span class="op">=</span>validation_dataset)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20
63/63 [==============================] - 8s 68ms/step - loss: 0.1827 - accuracy: 0.9495 - val_loss: 0.0608 - val_accuracy: 0.9802
Epoch 2/20
63/63 [==============================] - 6s 86ms/step - loss: 0.1705 - accuracy: 0.9565 - val_loss: 0.0893 - val_accuracy: 0.9752
Epoch 3/20
63/63 [==============================] - 4s 58ms/step - loss: 0.1815 - accuracy: 0.9490 - val_loss: 0.0665 - val_accuracy: 0.9777
Epoch 4/20
63/63 [==============================] - 5s 84ms/step - loss: 0.1668 - accuracy: 0.9490 - val_loss: 0.0722 - val_accuracy: 0.9827
Epoch 5/20
63/63 [==============================] - 4s 54ms/step - loss: 0.1477 - accuracy: 0.9500 - val_loss: 0.0685 - val_accuracy: 0.9802
Epoch 6/20
63/63 [==============================] - 4s 56ms/step - loss: 0.2211 - accuracy: 0.9440 - val_loss: 0.0679 - val_accuracy: 0.9827
Epoch 7/20
63/63 [==============================] - 5s 84ms/step - loss: 0.2229 - accuracy: 0.9450 - val_loss: 0.0966 - val_accuracy: 0.9728
Epoch 8/20
63/63 [==============================] - 4s 55ms/step - loss: 0.2209 - accuracy: 0.9475 - val_loss: 0.0654 - val_accuracy: 0.9790
Epoch 9/20
63/63 [==============================] - 4s 55ms/step - loss: 0.2068 - accuracy: 0.9445 - val_loss: 0.1565 - val_accuracy: 0.9629
Epoch 10/20
63/63 [==============================] - 5s 83ms/step - loss: 0.1718 - accuracy: 0.9550 - val_loss: 0.0715 - val_accuracy: 0.9790
Epoch 11/20
63/63 [==============================] - 4s 54ms/step - loss: 0.2201 - accuracy: 0.9465 - val_loss: 0.0729 - val_accuracy: 0.9802
Epoch 12/20
63/63 [==============================] - 4s 56ms/step - loss: 0.1931 - accuracy: 0.9480 - val_loss: 0.0639 - val_accuracy: 0.9827
Epoch 13/20
63/63 [==============================] - 5s 78ms/step - loss: 0.1726 - accuracy: 0.9550 - val_loss: 0.0722 - val_accuracy: 0.9790
Epoch 14/20
63/63 [==============================] - 4s 55ms/step - loss: 0.1682 - accuracy: 0.9500 - val_loss: 0.0582 - val_accuracy: 0.9839
Epoch 15/20
63/63 [==============================] - 4s 56ms/step - loss: 0.1141 - accuracy: 0.9610 - val_loss: 0.0696 - val_accuracy: 0.9827
Epoch 16/20
63/63 [==============================] - 4s 67ms/step - loss: 0.1543 - accuracy: 0.9610 - val_loss: 0.0549 - val_accuracy: 0.9839
Epoch 17/20
63/63 [==============================] - 5s 68ms/step - loss: 0.1380 - accuracy: 0.9590 - val_loss: 0.0560 - val_accuracy: 0.9839
Epoch 18/20
63/63 [==============================] - 4s 56ms/step - loss: 0.2115 - accuracy: 0.9465 - val_loss: 0.0724 - val_accuracy: 0.9827
Epoch 19/20
63/63 [==============================] - 4s 56ms/step - loss: 0.1376 - accuracy: 0.9585 - val_loss: 0.0737 - val_accuracy: 0.9802
Epoch 20/20
63/63 [==============================] - 6s 91ms/step - loss: 0.2048 - accuracy: 0.9480 - val_loss: 0.0582 - val_accuracy: 0.9777</code></pre>
</div>
</div>
<p>Graph:</p>
<div class="cell" data-outputid="42be077e-6d0c-4045-857c-28714ac77929" data-execution_count="48">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"accuracy"</span>], label <span class="op">=</span> <span class="st">"training"</span>)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_accuracy"</span>], label <span class="op">=</span> <span class="st">"validation"</span>)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"epoch"</span>, ylabel <span class="op">=</span> <span class="st">"accuracy"</span>)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>&lt;matplotlib.legend.Legend at 0x789194daa710&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-26-output-2.png" class="img-fluid"></p>
</div>
</div>
<section id="comments-on-model-4" class="level2">
<h2 class="anchored" data-anchor-id="comments-on-model-4">Comments on Model 4:</h2>
<ul>
<li><strong><em>The accuracy of my model stabilized between 96% and 99%</em></strong></li>
<li>This accuracy is far greater than <code>model1</code> and any of my other models</li>
<li>No overfitting issues seem to be present!</li>
</ul>
</section>
</section>
<section id="evaluating-testing-data-using-best-model" class="level1">
<h1>6. Evaluating Testing Data Using Best Model</h1>
<p>Moment of truth, let’s use our most recent and best model to evaluate it on testing data!</p>
<div class="cell" data-outputid="8f1a4e8c-81df-4551-d8ed-887a37299bb9" data-execution_count="49">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>model4.evaluate(test_dataset, verbose<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>6/6 [==============================] - 0s 39ms/step - loss: 0.0788 - accuracy: 0.9844</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>[0.0787581279873848, 0.984375]</code></pre>
</div>
</div>
<p>Our accuracy is 98.4%, which is pretty good!</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>