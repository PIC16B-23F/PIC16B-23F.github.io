[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "PIC 16B - 2023 Fall Blog"
  },
  {
    "objectID": "posts/quarto/index.html",
    "href": "posts/quarto/index.html",
    "title": "Hello, Quarto",
    "section": "",
    "text": "In this post, we’ll get set up with Quarto.\nQuarto is a static site converter, which you can use to turn plaintext documents into attractive webpages. You should have already installed Quarto and signed up for Quarto Pub when completing the software installation (details in BruinLearn)."
  },
  {
    "objectID": "posts/quarto/index.html#make-a-blog",
    "href": "posts/quarto/index.html#make-a-blog",
    "title": "Hello, Quarto",
    "section": "Make a blog",
    "text": "Make a blog\nThis should be very straightforward using the instructions at this link.\nAll you need to do is run the following code at the terminal.\nquarto create-project myblog --type website:blog\nThen once a folder appears, run this line.\nquarto preview myblog\nFeel free to replace myblog with a different name.\nquarto preview should open up a link that looks like http://localhost:6832 in your web browser. The port number probably looks different."
  },
  {
    "objectID": "posts/quarto/index.html#publish-on-quarto-pub",
    "href": "posts/quarto/index.html#publish-on-quarto-pub",
    "title": "Hello, Quarto",
    "section": "Publish on Quarto Pub",
    "text": "Publish on Quarto Pub\nNow, run this line on your terminal in the same directory.\nquarto publish myblog\nWhen prompted, select these options.\n? Provider: › Quarto Pub\n? Authorize (Y/n) › Yes\nFinally, the terminal should print out something like this:\n[✓] Creating quarto-pub site\n[✓] Preparing to publish site\n[✓] Uploading files (complete)\n[✓] Deploying published site\n[✓] Published site: https://quartopub.com/sites/[...]\n[✓] Account site updated: https://[Quarto Pub username].quarto.pub\nGo to the website on the last line, and if you see a webpage there, congrats! Your blog is up and running. At the moment, it’s just a copy of the template, so it’s not personalized in any way."
  },
  {
    "objectID": "posts/quarto/index.html#edit-a-post",
    "href": "posts/quarto/index.html#edit-a-post",
    "title": "Hello, Quarto",
    "section": "Edit a post",
    "text": "Edit a post\nPreview your blog again:\nquarto preview myblog\nThen edit the welcome page in posts/welcome/index.qmd. Any sort of change will do.\nOnce you save the file, you’ll see that the preview page on the web browser is automatically updated.\nYou can also add a new page following instructions in this post."
  },
  {
    "objectID": "posts/quarto/index.html#publish-again",
    "href": "posts/quarto/index.html#publish-again",
    "title": "Hello, Quarto",
    "section": "Publish again",
    "text": "Publish again\nOnce you’ve made all these additions, publish the result again using quarto publish. In a few minutes, you should see your new post on your website."
  },
  {
    "objectID": "posts/hw0/index.html",
    "href": "posts/hw0/index.html",
    "title": "Homework 0",
    "section": "",
    "text": "In this blog post assignment, you’ll create a short post for your new website. The primary purpose is to give you some practice working with Quarto blogging with Python code.\nMake sure to check the “Specifications” section at the bottom of this assignment for an explicit list of criteria that your blog post must meet in order to receive credit."
  },
  {
    "objectID": "posts/hw0/index.html#complete-the-hello-quarto-activity",
    "href": "posts/hw0/index.html#complete-the-hello-quarto-activity",
    "title": "Homework 0",
    "section": "1. Complete the Hello, Quarto activity",
    "text": "1. Complete the Hello, Quarto activity\nYour first step should be to complete the Hello Quarto activity to help you get familiar with blogging with Quarto. If you already completed this activity in Discussion, then you can skip to the next step.\nIf you haven’t done so already, now is a good time to modify your site. Look around the site’s files and see if you can figure out how to modify the About page and the blog’s title from about.qmd and _quarto.yml.\nSee these pages for help: about page, config options.\nIf you are comfortable with css, then you can directly modify style.css and other files in the repo.\nAll this is optional, and it’s not necessary to put your real name or real photo anywhere on the site."
  },
  {
    "objectID": "posts/hw0/index.html#create-a-post",
    "href": "posts/hw0/index.html#create-a-post",
    "title": "Homework 0",
    "section": "2. Create a post",
    "text": "2. Create a post\nCreate a simple blog post, using the instructions and demonstrations here. Here is the prompt for your post:\n\nWrite a tutorial explaining how to construct an interesting data visualization of the Palmer Penguins data set.\n\nYou can read the data into Python by running:\nimport pandas as pd\nurl = \"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/palmer_penguins.csv\"\npenguins = pd.read_csv(url)\nYour visualization does not have to be complex or fancy, but it should be highly readable and appropriately labeled.\nYour post should include the image directly under the code that generates it, as demonstrated here.\nThere will be two Gradescope assignments open for submission, one for PDF, and the other for code portion (as a programming assignment). You have to submit both of them for your homework to be graded.\n\nFor the PDF assingment, please submit your newly-created blog page printed as PDF. You do not need to publish your blog to the web for the homework. It is enough to print the preview page as a PDF and submit on Gradescope. If you want to publish it online, you are welcome to do so.\nFor the programming assignment, please submit any code file you wrote for your homework. All the .py file, .ipynb file, or .qmd files all included. The grader should be able to reproduce your result from the code portion you submitted.\n\n\nHint\nThe easiest way to create a post like this is to solve the problem in a Jupyter Notebook or Python script first, and then transfer the results over to your blog."
  },
  {
    "objectID": "posts/hw0/index.html#format",
    "href": "posts/hw0/index.html#format",
    "title": "Homework 0",
    "section": "Format",
    "text": "Format\n\nYou have to submit the PDF-printed version of your Quarto blog. Anything else will receive “In Progress” grade at best, incuding:\n\n\nJupyter notebook or JupyterLab screen printed\nHTML-converted Jupyter notebook printed\nPDF-converted Jupyter notebook or JupyterLab\nPDF generated directly from Quarto\n\n\nYou have to submit code necessary to reproduce your results."
  },
  {
    "objectID": "posts/hw0/index.html#coding-problem",
    "href": "posts/hw0/index.html#coding-problem",
    "title": "Homework 0",
    "section": "Coding Problem",
    "text": "Coding Problem\n\nThe plot is readable and contains axis labels, a title, and a legend if appropriate."
  },
  {
    "objectID": "posts/hw0/index.html#style-and-documentation",
    "href": "posts/hw0/index.html#style-and-documentation",
    "title": "Homework 0",
    "section": "Style and Documentation",
    "text": "Style and Documentation\n\nRepeated operations should be enclosed in functions.\nFor-loops are minimized by making full use of vectorized operations for Numpy arrays and Pandas data frames.\nHelpful comments are supplied throughout the code. Docstrings are supplied for any functions and classes you define."
  },
  {
    "objectID": "posts/hw0/index.html#writing",
    "href": "posts/hw0/index.html#writing",
    "title": "Homework 0",
    "section": "Writing",
    "text": "Writing\n\nThe overall post is written in engaging and unambiguous English prose. There is written explanation throughout the post, such that a PIC16A student could learn to perform the demonstrated tasks by reading the post.\nEach block of code has a clearly-explained purpose.\nThe post is organized into clearly delimited sections using markdown headers (#), making it easier for the reader to navigate."
  },
  {
    "objectID": "posts/hw2/index.html",
    "href": "posts/hw2/index.html",
    "title": "Homework 2: Web Scraping",
    "section": "",
    "text": "What’s your favorite movie or TV show? Wouldn’t it be nice to find more shows that you might like to watch, based on ones you know you like? Tools that address questions like this are often called “recommender systems.” Powerful, scalable recommender systems are behind many modern entertainment and streaming services, such as Netflix and Spotify. While most recommender systems these days involve machine learning, there are also ways to make recommendations that don’t require such complex tools.\nIn this Blog Post, you’ll use webscraping to answer the following question:\nThe idea of this question is that, if TV show Y has many of the same actors as TV show X, and you like X, you might also enjoy Y.\nThis post has two parts. In the first, larger part, you’ll write a webscraper for finding shared actors on TMDB. In the second, smaller part, you’ll use the results from your scraper to make recommendations.\nDon’t forget to check the Specifications for a complete list of what you need to do to obtain full credit. As usual, this Blog Post should be printed as PDF from your PIC16B Blog preview screen, and you need to submit any code you wrote as well."
  },
  {
    "objectID": "posts/hw2/index.html#setup",
    "href": "posts/hw2/index.html#setup",
    "title": "Homework 2: Web Scraping",
    "section": "1. Setup",
    "text": "1. Setup\n\n1.1. Locate the Starting TMDB Page\nPick your favorite movie or TV show, and locate its TMDB page by searching on https://www.themoviedb.org/. For example, my favorite movie is Harry Potter and the Sorcerer’sPhilosopher’s Stone. Its TMDB page is at:\nhttps://www.themoviedb.org/movie/671-harry-potter-and-the-philosopher-s-stone/\nSave this URL for a moment.\n\n\n1.2. Dry-Run Navigation\nNow, we’re just going to practice clicking through the navigation steps that our scraper will take.\nFirst, click on the Full Cast & Crew link. This will take you to a page with URL of the form\n&lt;original_url&gt;cast/\nNext, scroll until you see the Cast section. Click on the portrait of one of the actors. This will take you to a page with a different-looking URL. For example, the URL for Alan Rickman, who played Severus Snape, is\nhttps://www.themoviedb.org/person/4566-alan-rickman\nFinally, scroll down until you see the actor’s Acting section. Note the titles of a few movies and TV shows in this section.\nOur scraper is going to replicate this process. Starting with your favorite movie or TV show, it’s going to look at all the actors in that movie or TV show, and then log all the other movies or TV shows that they worked on.\nAt this point, it would be a good idea for you to use the Developer Tools on your browser to inspect individual HTML elements and look for patterns among the names you are looking for.\n\n\n1.3. Initialize Your Project\n\nOpen a terminal and type:\n\nconda activate PIC16B-2\nscrapy startproject TMDB_scraper\ncd TMDB_scraper\nThis will create quite a lot of files, but you don’t really need to touch most of them. However, you must submit the entire TMDB_scraper folder for the code part.\n\n\n1.4. Tweak Settings\nFor now, add the following line to the file settings.py:\nCLOSESPIDER_PAGECOUNT = 20\nThis line just prevents your scraper from downloading too much data while you’re still testing things out. You’ll remove this line later.\nHint: Later on, you may run into 403 Forbidden errors once the website detects that you’re a bot. See these links (link1, link2, link3, link4) for how to work around that issue. The easiest solution is changing one line in setting.py. You might see this when you run scrapy shell as well, so keep an eye out for 403! Remember, you want your status to be 200 OK. If they know that you are on Python, they will certainly try to block you."
  },
  {
    "objectID": "posts/hw2/index.html#write-your-scraper",
    "href": "posts/hw2/index.html#write-your-scraper",
    "title": "Homework 2: Web Scraping",
    "section": "2. Write Your Scraper",
    "text": "2. Write Your Scraper\nCreate a file inside the spiders directory called tmdb_spider.py. Add the following lines to the file:\n# to run \n# scrapy crawl tmdb_spider -o movies.csv\n\nimport scrapy\n\nclass TmdbSpider(scrapy.Spider):\n    name = 'tmdb_spider'\n    \n    start_urls = ['https://www.themoviedb.org/movie/671-harry-potter-and-the-philosopher-s-stone/']\nReplace the entry of start_urls with the URL corresponding to your favorite movie or TV show.\nNow, implement three parsing methods for the TmdbSpider class.\n\nparse(self, response) should assume that you start on a movie page, and then navigate to the Full Cast & Crew page. Remember that this page has url &lt;movie_url&gt;cast. (You are allowed to hardcode that part.) Once there, the parse_full_credits(self,response) should be called, by specifying this method in the callback argument to a yielded scrapy.Request. The parse() method does not return any data. This method should be no more than 5 lines of code, excluding comments and docstrings.\nparse_full_credits(self, response) should assume that you start on the Full Cast & Crew page. Its purpose is to yield a scrapy.Request for the page of each actor listed on the page. Crew members are not included. The yielded request should specify the method parse_actor_page(self, response) should be called when the actor’s page is reached. The parse_full_credits() method does not return any data. This method should be no more than 5 lines of code, excluding comments and docstrings.\nparse_actor_page(self, response) should assume that you start on the page of an actor. It should yield a dictionary with two key-value pairs, of the form {\"actor\" : actor_name, \"movie_or_TV_name\" : movie_or_TV_name}. The method should yield one such dictionary for each of the movies or TV shows on which that actor has worked. Note that you will need to determine both the name of the actor and the name of each movie or TV show. This method should be no more than 15 lines of code, excluding comments and docstrings.\n\nProvided that these methods are correctly implemented, you can run the command\nscrapy crawl tmdb_spider -o results.csv\nto create a .csv file with a column for actors and a column for movies or TV shows.\nExperimentation in the scrapy shell is strongly recommended.\n\nChallenge\nIf you’re looking for a challenge, think about ways that may make your recommendations more accurate. Consider scraping the number of episodes as well or limiting the number of actors you get per show to make sure you only get the main series cast."
  },
  {
    "objectID": "posts/hw2/index.html#make-your-recommendations",
    "href": "posts/hw2/index.html#make-your-recommendations",
    "title": "Homework 2: Web Scraping",
    "section": "3. Make Your Recommendations",
    "text": "3. Make Your Recommendations\nOnce your spider is fully written, comment out the line\nCLOSESPIDER_PAGECOUNT = 20\nin the settings.py file. Then, the command\nscrapy crawl tmdb_spider -o results.csv\nwill run your spider and save a CSV file called results.csv, with columns for actor names and the movies and TV shows on which they worked.\nOnce you’re happy with the operation of your spider, compute a sorted list with the top movies and TV shows that share actors with your favorite movie or TV show. For example, it may have two columns: one for “movie names” and “number of shared actors”.\nFeel free to be creative. You can show a pandas data frame, a chart using matplotlib or plotly, or any other sensible display of the results."
  },
  {
    "objectID": "posts/hw2/index.html#blog-post",
    "href": "posts/hw2/index.html#blog-post",
    "title": "Homework 2: Web Scraping",
    "section": "4. Blog Post",
    "text": "4. Blog Post\nIn your blog post, you should describe how your scraper works, as well as the results of your analysis. When describing your scraper, I recommend dividing it up into the three distinct parsing methods, and discussing them one-by-one. For example:\n\nIn this blog post, I’m going to make a super cool web scraper… Here’s a link to my project repository… Here’s how we set up the project…\n&lt;implementation of parse()&gt;\nThis method works by…\n\n\n&lt;implementation of parse_full_credits()&gt;\nTo write this method, I…\n\nIn addition to describing your scraper, your Blog Post should include a table or visualization of numbers of shared actors.\nRemember that this post is still a tutorial, in which you guide your reader through the process of setting up and running the scraper. Don’t forget to tell them how to create the project and run the scraper!"
  },
  {
    "objectID": "posts/hw2/index.html#format",
    "href": "posts/hw2/index.html#format",
    "title": "Homework 2: Web Scraping",
    "section": "Format",
    "text": "Format\n\nYou have to submit the PDF-printed version of your Quarto blog. Anything else will receive “In Progress” grade at best, incuding:\n\n\nJupyter notebook or JupyterLab screen printed\nHTML-converted Jupyter notebook printed\nPDF-converted Jupyter notebook or JupyterLab\nPDF generated directly from Quarto\n\n\nYou have to submit code necessary to reproduce your results."
  },
  {
    "objectID": "posts/hw2/index.html#coding-problem",
    "href": "posts/hw2/index.html#coding-problem",
    "title": "Homework 2: Web Scraping",
    "section": "Coding Problem",
    "text": "Coding Problem\n\nEach of the three parsing methods appear logically and correctly implemented.\nparse() is implemented in no more than 5 lines.\nparse_full_credits() is implemented in no more than 5 lines.\nparse_actor_page() is implemented in no more than 15 lines.\nA table or list of results or pandas dataframe is shown.\nA visualization with matplotlib, plotly, or seaborn is shown."
  },
  {
    "objectID": "posts/hw2/index.html#style-and-documentation",
    "href": "posts/hw2/index.html#style-and-documentation",
    "title": "Homework 2: Web Scraping",
    "section": "Style and Documentation",
    "text": "Style and Documentation\n\nEach of the three parse methods has a short docstring describing its assumptions (e.g. what kind of page it is meant to parse) and its effect, including navigation and data outputs.\nEach of the three parse methods has helpful comments for understanding how each chunk of code operates."
  },
  {
    "objectID": "posts/hw2/index.html#writing",
    "href": "posts/hw2/index.html#writing",
    "title": "Homework 2: Web Scraping",
    "section": "Writing",
    "text": "Writing\n\nThe blog post is written in tutorial format, in engaging and clear English. Grammar and spelling errors are acceptable within reason.\nThe blog post explains clearly how to set up the project, run the scraper, and access the results.\nThe blog post explains how each of the three parse methods works.\nBlog post has a descriptive title."
  },
  {
    "objectID": "posts/hw1/index.html",
    "href": "posts/hw1/index.html",
    "title": "Homework 1: Data Wrangling and Visualization",
    "section": "",
    "text": "In this blog post, you’ll create several interesting, interactive data graphics using the NOAA climate data that we’ve explored in the first several weeks of lectures."
  },
  {
    "objectID": "posts/hw1/index.html#instructions",
    "href": "posts/hw1/index.html#instructions",
    "title": "Homework 1: Data Wrangling and Visualization",
    "section": "Instructions",
    "text": "Instructions\nYour post should include not only code but also outputs (i.e. tables, figures) and expository writing that explains what you’re doing. Your target audience is a a student who has completed PIC16A but hasn’t taken PIC16B yet (i.e. you before the start of the quarter).\nSee the “Specifications” section at the bottom for a detailed list of specs."
  },
  {
    "objectID": "posts/hw1/index.html#create-a-database",
    "href": "posts/hw1/index.html#create-a-database",
    "title": "Homework 1: Data Wrangling and Visualization",
    "section": "1. Create a Database",
    "text": "1. Create a Database\nFirst, create a database with three tables: temperatures, stations, and countries. Refer back to lecture notes on how to access country names and relate them to temperature readings. Keep these as three separate tables in your database.\nMake sure to close the database connection after you are finished constructing it."
  },
  {
    "objectID": "posts/hw1/index.html#write-a-query-function",
    "href": "posts/hw1/index.html#write-a-query-function",
    "title": "Homework 1: Data Wrangling and Visualization",
    "section": "2. Write a Query Function",
    "text": "2. Write a Query Function\nWrite a function called query_climate_database() which accepts four arguments:\n\ncountry, a string giving the name of a country for which data should be returned.\nyear_begin and year_end, two integers giving the earliest and latest years for which should be returned.\nmonth, an integer giving the month of the year for which should be returned.\n\nThe return value of query_climate_database() is a Pandas dataframe of temperature readings for the specified country, in the specified date range, in the specified month of the year. This dataframe should have columns for:\n\nThe station name.\nThe latitude of the station.\nThe longitude of the station.\nThe name of the country in which the station is located.\nThe year in which the reading was taken.\nThe month in which the reading was taken.\nThe average temperature at the specified station during the specified year and month. (Note: the temperatures in the raw data are already averages by month, so you don’t have to do any aggregation at this stage.)\n\nHint: Inside the function, you would want to put in the given variables (like year_begin) inside the query string (like SELECT ... FROM ... WHERE ...). While you can do this with string concatenation, using the fancy Python f-strings will probably make your life easier. Be careful not to forget quotation marks for the string variables.\nFor example:\nquery_climate_database(country = \"India\", \n                       year_begin = 1980, \n                       year_end = 2020,\n                       month = 1)\n\n\n\n\n\n\n\n\n\nNAME\n\n\nLATITUDE\n\n\nLONGITUDE\n\n\nCountry\n\n\nYear\n\n\nMonth\n\n\nTemp\n\n\n\n\n\n\n0\n\n\nPBO_ANANTAPUR\n\n\n14.583\n\n\n77.633\n\n\nIndia\n\n\n1980\n\n\n1\n\n\n23.48\n\n\n\n\n1\n\n\nPBO_ANANTAPUR\n\n\n14.583\n\n\n77.633\n\n\nIndia\n\n\n1981\n\n\n1\n\n\n24.57\n\n\n\n\n2\n\n\nPBO_ANANTAPUR\n\n\n14.583\n\n\n77.633\n\n\nIndia\n\n\n1982\n\n\n1\n\n\n24.19\n\n\n\n\n3\n\n\nPBO_ANANTAPUR\n\n\n14.583\n\n\n77.633\n\n\nIndia\n\n\n1983\n\n\n1\n\n\n23.51\n\n\n\n\n4\n\n\nPBO_ANANTAPUR\n\n\n14.583\n\n\n77.633\n\n\nIndia\n\n\n1984\n\n\n1\n\n\n24.81\n\n\n\n\n…\n\n\n…\n\n\n…\n\n\n…\n\n\n…\n\n\n…\n\n\n…\n\n\n…\n\n\n\n\n3147\n\n\nDARJEELING\n\n\n27.050\n\n\n88.270\n\n\nIndia\n\n\n1983\n\n\n1\n\n\n5.10\n\n\n\n\n3148\n\n\nDARJEELING\n\n\n27.050\n\n\n88.270\n\n\nIndia\n\n\n1986\n\n\n1\n\n\n6.90\n\n\n\n\n3149\n\n\nDARJEELING\n\n\n27.050\n\n\n88.270\n\n\nIndia\n\n\n1994\n\n\n1\n\n\n8.10\n\n\n\n\n3150\n\n\nDARJEELING\n\n\n27.050\n\n\n88.270\n\n\nIndia\n\n\n1995\n\n\n1\n\n\n5.60\n\n\n\n\n3151\n\n\nDARJEELING\n\n\n27.050\n\n\n88.270\n\n\nIndia\n\n\n1997\n\n\n1\n\n\n5.70\n\n\n\n\n\n\n3152 rows × 7 columns"
  },
  {
    "objectID": "posts/hw1/index.html#write-a-geographic-scatter-function-for-yearly-temperature-increases",
    "href": "posts/hw1/index.html#write-a-geographic-scatter-function-for-yearly-temperature-increases",
    "title": "Homework 1: Data Wrangling and Visualization",
    "section": "3. Write a Geographic Scatter Function for Yearly Temperature Increases",
    "text": "3. Write a Geographic Scatter Function for Yearly Temperature Increases\nIn this part, you will write a function to create visualizations that address the following question:\n\nHow does the average yearly change in temperature vary within a given country?\n\nWrite a function called temperature_coefficient_plot(). This function should accept five explicit arguments, and an undetermined number of keyword arguments.\n\ncountry, year_begin, year_end, and month should be as in the previous part.\nmin_obs, the minimum required number of years of data for any given station. Only data for stations with at least min_obs years worth of data in the specified month should be plotted; the others should be filtered out. df.transform() plus filtering is a good way to achieve this task.\n**kwargs, additional keyword arguments passed to px.scatter_mapbox(). These can be used to control the colormap used, the mapbox style, etc.\n\nThe output of this function should be an interactive geographic scatterplot, constructed using Plotly Express, with a point for each station, such that the color of the point reflects an estimate of the yearly change in temperature during the specified month and time period at that station. A reasonable way to do this is to compute the first coefficient of a linear regression model at that station, as illustrated in the lecture where we used the .apply() method.\nFor example, after writing your function, you should be able to create a plot of estimated yearly increases in temperature during the month of January, in the interval 1980-2020, in India, as follows:\n# assumes you have imported necessary packages\ncolor_map = px.colors.diverging.RdGy_r # choose a colormap\n\nfig = temperature_coefficient_plot(\"India\", 1980, 2020, 1, \n                                   min_obs = 10,\n                                   zoom = 2,\n                                   mapbox_style=\"carto-positron\",\n                                   color_continuous_scale=color_map)\n\nfig.show()\n\n\nPlease pay attention to the following details:\n\nThe station name is shown when you hover over the corresponding point on the map.\nThe estimates shown in the hover are rounded to a sober number of significant figures.\nThe colorbar and overall plot have professional titles.\nThe colorbar is centered at 0, so that the “middle” of the colorbar (white, in this case) corresponds to a coefficient of 0.\n\nIt’s not necessary for your plot to look exactly like mine, but please attend to details such as these. Feel free to be creative about these labels, as well as the choice of colors, as long as your result is polished overall.\nYou are free (and indeed encouraged) to define additional functions as needed."
  },
  {
    "objectID": "posts/hw1/index.html#create-two-more-interesting-figures",
    "href": "posts/hw1/index.html#create-two-more-interesting-figures",
    "title": "Homework 1: Data Wrangling and Visualization",
    "section": "4. Create Two More Interesting Figures",
    "text": "4. Create Two More Interesting Figures\nCreate at least one more SQL query function and at least two more complex and interesting interactive data visualizations using the same data set. These plots must be of different types (e.g. line and bar, scatter and histogram, etc). The code to construct each visualization should be wrapped in functions, such that a user could create visualizations for different parts of the data by calling these functions with different arguments. At least one of these plots must involve multiple facets (i.e. multiple axes (in the sense of facets), each of which shows a subset of the data).\nAlongside the plots, you should clearly state a question that the plot addresses, similar to the question that we posed in Part 3. The questions for your two additional plots should be meaningfully different from each other and from the Part 3 question. You will likely want to define different query functions for extracting data for these new visualizations.\nIt is not necessary to create geographic plots for this part. Scatterplots, histograms, and line plots (among other choices) are all appropriate. Please make sure that they are complex, engaging, professional, and targeted to the questions you posed. In other words, push yourself! Don’t hesitate to ask your peers or talk to me if you’re having trouble coming up with questions or identifying plots that might be suitable for addressing those questions.\nThere will be two Gradescope assignments open for submission, one for PDF, and the other for code portion (as a programming assignment). You have to submit both of them for your homework to be graded.\n\nFor the PDF assingment, please submit your blog page printed as PDF. You do not need to publish your blog to the web for the homework. It is enough to print the preview page as a PDF and submit on Gradescope. If you want to publish it online, you are welcome to do so. However, please make sure your code is visible in full, i.e., not cuttoff, in your pdf.\nFor the programming assignment, please submit any code file you wrote and any HTML files generated within your post directory, but not the data files. All the .py file, .ipynb file, .qmd, .html files are included, but .csv files or .db files are not. The grader should be able to reproduce your result from the code portion you submitted."
  },
  {
    "objectID": "posts/hw1/index.html#tip",
    "href": "posts/hw1/index.html#tip",
    "title": "Homework 1: Data Wrangling and Visualization",
    "section": "Tip",
    "text": "Tip\nTo properly show figures in your blog, you may need to set your plotly renderer to iframe. To do so, run the following near the top of your notebook:\nimport plotly.io as pio\npio.renderers.default=\"iframe\""
  },
  {
    "objectID": "posts/hw1/index.html#format",
    "href": "posts/hw1/index.html#format",
    "title": "Homework 1: Data Wrangling and Visualization",
    "section": "Format",
    "text": "Format\n\nYou have to submit the PDF-printed version of your Quarto blog.\nYou have to submit code necessary to reproduce your results.\n\n\nAlso, you must submit any figures generated in the HTML format."
  },
  {
    "objectID": "posts/hw1/index.html#coding-problem",
    "href": "posts/hw1/index.html#coding-problem",
    "title": "Homework 1: Data Wrangling and Visualization",
    "section": "Coding Problem",
    "text": "Coding Problem\n\nThe query_climate_database() function is correctly defined according to the prompt.\nThere are two geographic scatterplots, one for 1980-2020 India that looks similar to the provided example, and another one for a different time and/or country.\nThe geographic scatterplots are correctly constructed and professionally labeled, including a title, hovers with rounded estimates, and a correctly centered colorbar.\nThere is at least one more sql query function defined.\nThere are two other interactive plots constructed using Plotly.\nOne of these plots involves the use of multiple facets.\nThe two other plots are wrapped in appropriate, user-friendly functions.\nEach of the two other interactive plots have descriptive titles and centered color maps when appropriate."
  },
  {
    "objectID": "posts/hw1/index.html#style-and-documentation",
    "href": "posts/hw1/index.html#style-and-documentation",
    "title": "Homework 1: Data Wrangling and Visualization",
    "section": "Style and Documentation",
    "text": "Style and Documentation\n\nRepeated operations should are enclosed in functions.\nFor-loops are minimized by making full use of vectorized operations for Numpy arrays and Pandas data frames.\nHelpful comments are supplied throughout the code. Docstrings are supplied for any functions and classes you define."
  },
  {
    "objectID": "posts/hw1/index.html#writing",
    "href": "posts/hw1/index.html#writing",
    "title": "Homework 1: Data Wrangling and Visualization",
    "section": "Writing",
    "text": "Writing\n\nThe overall post is written in engaging and unambiguous English prose. There is written explanation throughout the post, such that a PIC16A student could learn to perform the demonstrated tasks by reading the post.\n\nEach block of code has a clearly-explained purpose.\nThe post is organized into clearly delimited sections using markdown headers (#), making it easier for the reader to navigate.\n\nThe post has a different title from “Blog Post: Data Wrangling and Visualization” or “Blog Post 1”. Please rename it to something more relevant and specific to your data analysis."
  },
  {
    "objectID": "posts/composing/index.html",
    "href": "posts/composing/index.html",
    "title": "Creating Posts",
    "section": "",
    "text": "How to create technical posts that include Python code, explanatory text, and notes."
  },
  {
    "objectID": "posts/composing/index.html#directory",
    "href": "posts/composing/index.html#directory",
    "title": "Creating Posts",
    "section": "Directory",
    "text": "Directory\nYour posts should be placed in the posts/ directory of your website.\nIf you want to make a new page called bruin, then create a new folder named bruin/ inside posts/. For example:\nposts\n└───composing \n└───bruin &lt; new folder\n└───quarto\n└───software\n└───welcome"
  },
  {
    "objectID": "posts/composing/index.html#create-the-file",
    "href": "posts/composing/index.html#create-the-file",
    "title": "Creating Posts",
    "section": "Create the File",
    "text": "Create the File\nYou have two options with the folder bruin/.\nOption 1: Add a Jupyter Notebook named index.ipynb Since your homework posts will be based on previous work you did in a Jupyter notebook or Google colab, this will probably be the easier option for publishing homeworks.\nOption 2: Add a index.qmd text file But this is probably a better option for your group project blog post, and once you (hopefully) continue to build up your portfolio using this website.\nFor either options, make sure to add a header that looks like this to the top:\n---\ntitle: \"Creating posts\"\nauthor: \"Seyoon\"\ndate: \"2022-12-24\"\ncategories: [week 0, example]\n---\nIn Jupyter notebook, this header should be in a raw cell up top."
  },
  {
    "objectID": "posts/composing/index.html#markdown-styling",
    "href": "posts/composing/index.html#markdown-styling",
    "title": "Creating Posts",
    "section": "Markdown Styling",
    "text": "Markdown Styling\nYou can use Markdown to style basic text, much as you do in Jupyter Notebooks.\nLook into Quarto’s Markdown basics, Figures and Tables. You’re welcome to explore other pages that cover more complex concepts like Diagrams, Videos, and Callout Blocks."
  },
  {
    "objectID": "posts/composing/index.html#math",
    "href": "posts/composing/index.html#math",
    "title": "Creating Posts",
    "section": "Math",
    "text": "Math\nIf you are familiar with the \\[\\LaTeX\\] typesetting system, you can use many standard commands by enclosing them in double $ symbols. You can make both inline math like \\[\nf(x) = e^x\n\\] and display math like \\[\n\\sum_{i=1}^\\infty \\frac{1}{i^2} = \\frac{\\pi^2}{6}.\n\\]"
  },
  {
    "objectID": "posts/composing/index.html#images",
    "href": "posts/composing/index.html#images",
    "title": "Creating Posts",
    "section": "Images",
    "text": "Images\nYou can and should include images in your posts, especially in cases where you have created a data visualization. If the image is already available online, you can link to it using the syntax ![alt text](image_url):\n\n(Source: https://xkcd.com/353/)"
  },
  {
    "objectID": "posts/composing/index.html#code",
    "href": "posts/composing/index.html#code",
    "title": "Creating Posts",
    "section": "Code",
    "text": "Code\nThere are two main ways to insert code in your posts. When talking about a short concept, like the np.random.rand() function, you can type back ticks like this: `np.random.rand()`.\nTo create a larger block of code, use three consecutive backticks ``` to both open and close the code block. If you place the word “{python}” immediately after the opening code blocks, you’ll get attractive syntax highlighting:\n\ndef f(x):\n    \"\"\"\n    A cool function that multiples an input x by 2. \n    \"\"\"\n    return 2*x\n\ny = f(3)\nprint(y)\n\n6\n\n\nNot only that, once you render the page with Quarto, the code output will show up below. If that’s not what you want, use the word “python” instead of “{python}”\nLook at this other cool example from the Quarto tutorial.\nFor a demonstration of a line plot on a polar axis, see Figure 1.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PIC16B-23F",
    "section": "",
    "text": "Homework 2: Web Scraping\n\n\n\n\n\n\n\nHomework\n\n\n\n\n\n\n\n\n\n\n\nOct 14, 2023\n\n\n\n\n\n\n  \n\n\n\n\nHomework 1: Data Wrangling and Visualization\n\n\n\n\n\n\n\nHomework\n\n\n\n\n\n\n\n\n\n\n\nOct 7, 2023\n\n\n\n\n\n\n  \n\n\n\n\nHomework 0\n\n\n\n\n\n\n\nHomework\n\n\n\n\n\n\n\n\n\n\n\nOct 2, 2023\n\n\n\n\n\n\n  \n\n\n\n\nCreating Posts\n\n\n\n\n\n\n\nWeek 0\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2023\n\n\n\n\n\n\n  \n\n\n\n\nHello, Quarto\n\n\n\n\n\n\n\nWeek 0\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2023\n\n\n\n\n\n\nNo matching items"
  }
]